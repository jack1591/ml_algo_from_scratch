{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcdeb424-4a8f-4064-8170-0b296cbfafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6f548-77f3-4493-9d32-8dee91518ed1",
   "metadata": {},
   "source": [
    "## Собственная реализация решающего дерева для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2798071f-897a-40c5-9706-8a1bfb159c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from numba import njit\n",
    "class Node:\n",
    "    __slots__ = ('feature', 'threshold', 'left', 'right', 'value')\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature      # индекс признака для разбиения (у внутреннего узла)\n",
    "        self.threshold = threshold  # порог разбиения\n",
    "        self.left = left            # левое поддерево (Node)\n",
    "        self.right = right          # правое поддерево (Node)\n",
    "        self.value = value \n",
    "        \n",
    "class MyDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth = 5, min_samples_split = 2, min_samples_leaf = 1, criteria = 'gini'):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.criteria = self.gini_criteria\n",
    "\n",
    "    @staticmethod\n",
    "    @njit\n",
    "    def gini_criteria(total_by_class, total):\n",
    "        if total == 0:\n",
    "            return 0.0\n",
    "        parts = total_by_class / total\n",
    "        return 1 - np.sum(parts ** 2)\n",
    "\n",
    "\n",
    "    '''\n",
    "    1. Перебираем признаки\n",
    "    2. Получаем массив значений каждого признака у объектов\n",
    "    3. Сортируем его, сортируем таргет по этим индексам\n",
    "    4. Сначала слева - 0 элементов, справа - все\n",
    "    5. Бежим слева направо, после нахождения каждой группы одинаковых элементов считаем критерий качества данного разделения\n",
    "    6. Запоминаем лучший\n",
    "    '''\n",
    "\n",
    "    # indices - индексы элементов, которые входят в текущий узел\n",
    "\n",
    "    @staticmethod\n",
    "    @njit\n",
    "    def best_split_for_feature(sorted_features, sorted_labels, parent_score, n_classes, min_samples_leaf, criteria):\n",
    "        n_samples = len(sorted_features)\n",
    "        best_threshold = None\n",
    "        best_split = parent_score\n",
    "        left_border = 0\n",
    "\n",
    "        right_counts = np.bincount(sorted_labels, minlength = n_classes)\n",
    "        right_volume = n_samples\n",
    "        \n",
    "        left_counts = np.zeros_like(right_counts)\n",
    "        left_volume = 0\n",
    "        \n",
    "        while left_border < n_samples - 1:\n",
    "            start_value = sorted_features[left_border]\n",
    "            j = left_border\n",
    "            while j < n_samples and sorted_features[j] == start_value:\n",
    "                right_counts[sorted_labels[j]] -= 1\n",
    "                left_counts[sorted_labels[j]] += 1\n",
    "                right_volume -= 1\n",
    "                left_volume += 1\n",
    "                j+=1\n",
    "                \n",
    "            if left_volume >= min_samples_leaf and right_volume >= min_samples_leaf:\n",
    "                criteria_left = criteria(left_counts, left_volume)\n",
    "                criteria_right = criteria(right_counts, right_volume)\n",
    "                current_score = left_volume / n_samples * criteria_left + right_volume / n_samples * criteria_right\n",
    "\n",
    "                \n",
    "                if current_score < best_split:\n",
    "                    best_split = current_score\n",
    "                    if j < n_samples:\n",
    "                        best_threshold = (sorted_features[j] + start_value) / 2.0\n",
    "                    else:\n",
    "                        best_threshold = start_value\n",
    "                        \n",
    "            left_border = j\n",
    "        return best_threshold, best_split\n",
    "                \n",
    "    def find_best_split(self, X, y, indices, parent_score):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_split = parent_score\n",
    "        \n",
    "        n_samples = len(indices)\n",
    "        labels = y[indices]\n",
    "        \n",
    "        if n_samples < self.min_samples_leaf:\n",
    "            return best_feature, best_threshold\n",
    "        \n",
    "        for feature in range(X.shape[1]):\n",
    "            feature_values = X[indices, feature]\n",
    "\n",
    "            sorted_feature_idx = np.argsort(feature_values)\n",
    "            sorted_features = feature_values[sorted_feature_idx]\n",
    "            sorted_labels = labels[sorted_feature_idx]\n",
    "\n",
    "            current_threshold, current_split = self.best_split_for_feature(sorted_features, sorted_labels, parent_score, self.n_classes, self.min_samples_leaf, self.criteria)\n",
    "            if current_split < best_split:\n",
    "                best_feature = feature\n",
    "                best_threshold = current_threshold\n",
    "                best_split = current_split\n",
    "        return best_feature, best_threshold\n",
    "        \n",
    "    def build_tree(self, X, y, indices, depth):\n",
    "        n_samples = len(indices)\n",
    "        n_classes = len(np.unique(y[indices]))\n",
    "\n",
    "        if (n_classes == 1) or (depth >= self.max_depth) or (n_samples<self.min_samples_split):\n",
    "            most_common = np.bincount(y[indices]).argmax()\n",
    "            return Node(value = most_common)\n",
    "\n",
    "        parent_counts = np.bincount(y[indices], minlength = self.n_classes)\n",
    "        parent_score = self.criteria(parent_counts, n_samples)\n",
    "        \n",
    "        best_feature, best_threshold = self.find_best_split(X, y, indices, parent_score)\n",
    "        \n",
    "        if best_feature is None:  # не удалось найти разбиение\n",
    "            most_common = np.bincount(y[indices]).argmax()\n",
    "            return Node(value=most_common)\n",
    "            \n",
    "        feature_values = X[indices, best_feature]\n",
    "        left_indices = indices[feature_values <= best_threshold]\n",
    "        right_indices = indices[feature_values > best_threshold]\n",
    "\n",
    "        left_subtree = self.build_tree(X, y, left_indices, depth+1)\n",
    "        right_subtree = self.build_tree(X, y, right_indices, depth+1)\n",
    "        \n",
    "        return Node(feature = best_feature, threshold = best_threshold, left = left_subtree, right = right_subtree)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.root = self.build_tree(X, y, indices = np.arange(X.shape[0]), depth = 0)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)    \n",
    "        return np.array([self.predict_one(x, self.root) for x in X])\n",
    "\n",
    "    def predict_one(self, obj, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if obj[node.feature] <= node.threshold:\n",
    "            return self.predict_one(obj, node.left)\n",
    "        return self.predict_one(obj, node.right)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bf860-9694-42f4-b131-ed5877da0047",
   "metadata": {},
   "source": [
    "## Замерим качество работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52cbe6aa-62d0-414c-a2f2-becd4fe892ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cff2b6-15c2-47ff-a04b-421bf4d2b272",
   "metadata": {},
   "source": [
    "### Моя реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed54051d-d221-47b5-b693-8eada67d0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on cross_validation, (number of folds is 7): 0.9140104099453693\n",
      "CPU times: total: 1.27 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "my_tree_classifier = MyDecisionTreeClassifier()\n",
    "print(f'Accuracy on cross_validation, (number of folds is 7): {np.mean(cross_val_score(my_tree_classifier, X, y, cv = 7, scoring = 'accuracy'))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2410a-bb4a-46e9-a44e-6048ff1c4acb",
   "metadata": {},
   "source": [
    "### Готовая реализация в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe16dbc-ef27-44c3-ad81-9b4dfdaee7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on cross_validation, (number of folds is 7): 0.9350238740482641\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_classifier = DecisionTreeClassifier(max_depth = 5)\n",
    "print(f'Accuracy on cross_validation, (number of folds is 7): {np.mean(cross_val_score(tree_classifier, X, y, cv = 7, scoring = 'accuracy'))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbcbf74-740e-4e7b-ae91-eb5ce4fc25d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
